nc: 80
scales:
  # s: [0.50, 0.50, 1024] # 保持不变
  n: [0.50, 0.25, 1024] # 保持不变


backbone:
  - [-1, 1, Conv, [64, 3, 2]]
  - [-1, 1, Conv, [128, 3, 2]]
  - [-1, 2, C3k2, [256, False, 0.25]] # <-- 保留 C3k2 2个块

  # !!! 优化 1：移除 Layer 3 的 MoE，用更深的 C3k2 替代，降低浅层 FLOPs
  # - [-1, 3, C3k2, [256, False, 0.5]] # 使用 3个C3k2块，提升深度，压缩率0.5
  - [-1, 2, C3k2, [256, False, 0.25]] # 使用 3个C3k2块，提升深度，压缩率0.5


  - [-1, 1, Conv, [256, 3, 2]]
  - [-1, 2, C3k2, [512, False, 0.25]] 
  
  # Layer 6: 中层 MoE 保持 4 个专家，以防计算量剧增
  - [-1, 1, OptimizedMOEImproved, [512, 4, 2]] # 显式设置专家数4, TopK=2

  - [-1, 1, Conv, [512, 3, 2]]
  - [-1, 4, A2C2f, [512, True, 4]]
  
  # !!! 优化 2a：深层 Layer 9 增加专家到 8
  - [-1, 1, OptimizedMOEImproved, [512, 4, 2]] # 提升容量，FLOPs不变

  - [-1, 1, Conv, [1024, 3, 2]]
  - [-1, 4, A2C2f, [1024, True, 1]]
  
  # !!! 优化 2b：最深层 Layer 12 增加专家到 8
  - [-1, 1, OptimizedMOEImproved, [1024, 8, 2]] # 提升容量，FLOPs不变

head:
  # ... (头部保持不变)
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 9], 1, Concat, [1]]
  - [-1, 2, C3k2, [512, True]]

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]
  - [-1, 2, C3k2, [256, True]]

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 15], 1, Concat, [1]]
  - [-1, 2, C3k2, [512, True]]

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]
  - [-1, 2, C3k2, [512, True]]

  - [[18, 21, 24], 1, Detect, [nc]]